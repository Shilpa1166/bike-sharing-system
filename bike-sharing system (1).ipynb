{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "name": ""
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Step 1: Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\nfrom sklearn.preprocessing import LabelEncoder\n\n# Step 2: Load the dataset\ndf = pd.read_csv(\"data.csv\")\n\n# Step 3: Data Preprocessing\n# Convert 'weathersit' and 'season' into categorical variables with appropriate labels\ndf['weathersit'] = df['weathersit'].map({1: 'Clear', 2: 'Mist', 3: 'Light Snow', 4: 'Heavy Snow'})\ndf['season'] = df['season'].map({1: 'Spring', 2: 'Summer', 3: 'Fall', 4: 'Winter'})\n\n# Convert the 'yr' column to categorical (2018 and 2019) - Don't drop it as it could be important for predictions\ndf['yr'] = df['yr'].map({0: '2018', 1: '2019'})\n\n# Optional: Encoding categorical variables if necessary\n# We can use LabelEncoder for ordinal encoding or OneHotEncoding depending on the variables\nlabel_encoder = LabelEncoder()\ndf['season'] = label_encoder.fit_transform(df['season'])\ndf['weathersit'] = label_encoder.fit_transform(df['weathersit'])\ndf['yr'] = label_encoder.fit_transform(df['yr'])\n\n# Step 4: Target variable 'cnt' and feature selection\nX = df.drop(['cnt', 'casual', 'registered'], axis=1)  # Removing the target and individual user columns\ny = df['cnt']\n\n# Step 5: Train-Test Split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Step 6: Build the Linear Regression Model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Step 7: Predictions\ny_pred = model.predict(X_test)\n\n# Step 8: Evaluate Model\n# Calculate R-squared score\nr2 = r2_score(y_test, y_pred)\nprint(\"R-squared score: \", r2)\n\n# Optional: Plot residuals\nresiduals = y_test - y_pred\nplt.scatter(y_pred, residuals)\nplt.xlabel('Predicted Values')\nplt.ylabel('Residuals')\nplt.title('Residual Plot')\nplt.show()\n\n# Step 9: Conclusion\n# You can now analyze the R-squared score to understand how well the model is performing.\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Step 1: Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\nfrom sklearn.preprocessing import LabelEncoder\n\n# Step 2: Load the dataset\n# Assuming the data is in a CSV file called \"bike_sharing_data.csv\"\ndf = pd.read_csv(\"data.csv\")\n\n# Step 3: Data Preprocessing\n# Convert 'weathersit' and 'season' into categorical variables with appropriate labels\ndf['weathersit'] = df['weathersit'].map({1: 'Clear', 2: 'Mist', 3: 'Light Snow', 4: 'Heavy Snow'})\ndf['season'] = df['season'].map({1: 'Spring', 2: 'Summer', 3: 'Fall', 4: 'Winter'})\n\n# Convert the 'yr' column to categorical (2018 and 2019) - Don't drop it as it could be important for predictions\ndf['yr'] = df['yr'].map({0: '2018', 1: '2019'})\n\n# Optional: Encoding categorical variables if necessary\n# We can use LabelEncoder for ordinal encoding or OneHotEncoding depending on the variables\nlabel_encoder = LabelEncoder()\ndf['season'] = label_encoder.fit_transform(df['season'])\ndf['weathersit'] = label_encoder.fit_transform(df['weathersit'])\ndf['yr'] = label_encoder.fit_transform(df['yr'])\n\n# Step 4: Target variable 'cnt' and feature selection\nX = df.drop(['cnt', 'casual', 'registered'], axis=1)  # Removing the target and individual user columns\ny = df['cnt']\n\n# Step 5: Train-Test Split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Step 6: Build the Linear Regression Model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Step 7: Predictions\ny_pred = model.predict(X_test)\n\n# Step 8: Evaluate Model\n# Calculate R-squared score\nr2 = r2_score(y_test, y_pred)\nprint(\"R-squared score: \", r2)\n\n# Optional: Plot residuals\nresiduals = y_test - y_pred\nplt.scatter(y_pred, residuals)\nplt.xlabel('Predicted Values')\nplt.ylabel('Residuals')\nplt.title('Residual Plot')\nplt.show()\n\n# Step 9: Conclusion\n# The R-squared value indicates the goodness of fit of the model. \n# A higher value of R-squared means a better fit of the model to the data.\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}